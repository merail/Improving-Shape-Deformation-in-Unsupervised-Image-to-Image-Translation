{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANimorph1002.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merail/Improving-Shape-Deformation-in-Unsupervised-Image-to-Image-Translation/blob/master/GANimorph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5HVkqg1jPB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required modules\n",
        "import numpy as np \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.init import kaiming_normal_, calculate_gain\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable, grad\n",
        "\n",
        "from functools import *\n",
        "from scipy.io import loadmat\n",
        "\n",
        "import os, time, imageio\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUc3BJ4EjfuZ",
        "colab_type": "code",
        "outputId": "d0883a37-9de6-4aea-db08-6999d9b1cc6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CJ3Y5sL2gz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Initializer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Initializer, self).__init__()\n",
        "    \n",
        "  def forward(self, layer):\n",
        "    if layer.__class__.__name__.find('Conv2D') != -1:\n",
        "      kaiming_normal_(layer.weight, a = calculate_gain(\"leaky_relu\", negative_slope))\n",
        "    if layer.__class__.__name__.find('ConvTransposed2D') != -1:\n",
        "      kaiming_normal_(layer.weight, a = calculate_gain(\"relu\"))\n",
        "    if layer.__class__.__name__.find('InstanceNorm') != -1:\n",
        "      nn.init.normal_(layer.weight, mean=1.0, std=0.002)\n",
        "      layer.bias.data.zero_()\n",
        "\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMu-zPCfE1fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Store():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def make_store(self):\n",
        "    current_time = time.strftime('%Y-%m-%d %H%M%S')\n",
        "    epoch = 0\n",
        "    \n",
        "    samples_directory = os.path.join(store_directory, current_time, 'samples')\n",
        "    weights_directory = os.path.join(store_directory, current_time, 'weights')\n",
        "    losses_directory = os.path.join(store_directory, current_time, 'losses')\n",
        "    os.makedirs(samples_directory)\n",
        "    os.makedirs(weights_directory)\n",
        "    os.makedirs(losses_directory)\n",
        "    \n",
        "    self.store_settings = {'epoch': epoch, 'samples_directory': samples_directory, \n",
        "            'weights_directory': weights_directory, 'losses_directory': losses_directory}\n",
        "    \n",
        "    return self.store_settings\n",
        "    \n",
        "  def restore_model(self):\n",
        "    pattern = restore_file.split('-')\n",
        "    epoch = int(pattern[2])\n",
        "\n",
        "    samples_directory = os.path.join(restore_directory, 'samples')\n",
        "    weights_directory = os.path.join(restore_directory, 'weights')\n",
        "    losses_directory = os.path.join(restore_directory, 'losses')\n",
        "    G_model = os.path.join(weights_directory, restore_file + '-G.pth')\n",
        "    D_model = os.path.join(weights_directory, restore_file + '-D.pth')\n",
        "    \n",
        "    G.load_state_dict(torch.load(G_model))\n",
        "    D.load_state_dict(torch.load(D_model))\n",
        "\n",
        "    print('Restored from directory: %s, pattern: %s' % (restore_directory, restore_file))\n",
        "    \n",
        "    self.store_settings = {'epoch': epoch, 'samples_directory': samples_directory, \n",
        "            'weights_directory': weights_directory, 'losses_directory': losses_directory}\n",
        "    \n",
        "    return self.store_settings\n",
        "  \n",
        "  def save_model(self, it):\n",
        "    g_file = os.path.join(self.store_settings['weights_directory'], '-%s' % (str(it).zfill(6))) + '-G.pth'\n",
        "    torch.save(G.state_dict(), g_file)\n",
        "\n",
        "    d_file = os.path.join(self.store_settings['weights_directory'], '-%s' % (str(it).zfill(6))) + '-D.pth'\n",
        "    torch.save(D.state_dict(), d_file)\n",
        "    \n",
        "  def save_losses(self, it, losses_type, losses):\n",
        "    path = os.path.join(self.store_settings['losses_directory'], '-%s' % (str(it).zfill(6))) + '-' + losses_type + '.txt'\n",
        "    file = open(path, 'w')\n",
        "    for item in losses:\n",
        "      file.write(\"%s\\n\" % item)\n",
        "    file.close()\n",
        "    losses = []\n",
        "\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr1yvIeSok3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Generator, self).__init__()\n",
        "\n",
        "      self.initializer = Initializer()\n",
        "      subDepth = 3\n",
        "      i = 1\n",
        "\n",
        "      self.model = nn.ModuleList()\n",
        "\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = input_channel_size, out_channels = NF, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "                                   nn.InstanceNorm2d(NF, affine=True),\n",
        "                                   nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF, out_channels = NF * 2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "                                   nn.InstanceNorm2d(NF * 2, affine=True),\n",
        "                                   nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "\n",
        "      self.model += [self.build_res_group(subDepth, NF * 2, NF * 2, i)]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF*2, out_channels = NF * 4, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 4, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "\n",
        "      self.model += [self.build_res_group(subDepth, NF * 4, NF * 4, i)]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 4, out_channels = NF * 8, kernel_size = 4, stride = 2, padding = 1, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "\n",
        "      self.model += [self.build_res_group(subDepth, NF * 8, NF * 8, i)]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.ConvTranspose2d(in_channels = NF * 8, out_channels = NF * 4, kernel_size = 2, stride=2, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 4, affine=True),\n",
        "                     nn.ReLU())]\n",
        "\n",
        "      self.model += [self.build_res_group(subDepth, NF * 8, NF * 4, i)]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.ConvTranspose2d(in_channels = NF * 4, out_channels = NF * 2, kernel_size = 2, stride=2, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 2, affine=True),\n",
        "                     nn.ReLU())]\n",
        "\n",
        "      self.model += [self.build_res_group(subDepth, NF * 4, NF * 2, i)]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.ConvTranspose2d(in_channels = NF * 2, out_channels = NF, kernel_size = 2, stride=2, bias=False),\n",
        "                     nn.InstanceNorm2d(NF, affine=True),\n",
        "                     nn.ReLU())]\n",
        "\n",
        "      self.model += [nn.Sequential(nn.ConvTranspose2d(in_channels = NF, out_channels = 3, kernel_size = 2, stride=2, bias=False),\n",
        "                     nn.InstanceNorm2d(3, affine=True),\n",
        "                     nn.Sigmoid())]\n",
        "\n",
        "      for i in range(0, len(self.model)):\n",
        "        for j in range(0, len(self.model[i])):\n",
        "            self.model[i][j] = self.initializer(self.model[i][j])\n",
        "      \n",
        "    def build_res_group(self, depth, in_channels, out_channels, i):\n",
        "      residual_group = nn.ModuleList()\n",
        "      buf_channels = in_channels\n",
        "\n",
        "      for k in range(depth):\n",
        "        for m in range(depth):\n",
        "          if ((m + 1) % 3 == 0):\n",
        "            residual_group += [nn.Conv2d(in_channels = (buf_channels + out_channels), out_channels = in_channels, kernel_size = 3, stride = 1, padding = 1, bias=False)]\n",
        "            residual_group += [nn.InstanceNorm2d(in_channels, affine=True)]\n",
        "            residual_group += [nn.LeakyReLU(negative_slope = negative_slope)]\n",
        "            buf_channels = out_channels\n",
        "          else:\n",
        "            residual_group += [nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, stride = 1, padding = 1, bias=False)]\n",
        "            residual_group += [nn.InstanceNorm2d(out_channels, affine=True)]\n",
        "            residual_group += [nn.LeakyReLU(negative_slope = negative_slope)]\n",
        "            \n",
        "            in_channels = out_channels\n",
        "      \n",
        "      return nn.Sequential(*residual_group)\n",
        "\n",
        "    def forward(self, x):\n",
        "      for i in range(0, len(self.model)):\n",
        "        if i == 3:\n",
        "          skip_in_1 = x\n",
        "        if i == 5:\n",
        "          skip_in_2 = x\n",
        "        if i == 8:\n",
        "          x = torch.cat((x, skip_in_2), 1)\n",
        "        if i == 10:  \n",
        "          x = torch.cat((x, skip_in_1), 1)\n",
        "        \n",
        "        for j in range (0, len(self.model[i])):\n",
        "          if ((j % 9) == 0):\n",
        "            skip_for_residual_block = x\n",
        "          if ((j + 3) % 9 == 0):\n",
        "            x = torch.cat((x, skip_for_residual_block), 1)\n",
        "          x = self.model[i][j](x)\n",
        "          # print(i, \" \", j)\n",
        "          #print(x)\n",
        "          #print(\"gen\", x.shape)\n",
        "\n",
        "        #print(\"============\")\n",
        "        \n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDB6pwAnGBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Discriminator, self).__init__()\n",
        "\n",
        "      subDepth = 3\n",
        "      self.width = 16\n",
        "\n",
        "      self.initializer = Initializer()\n",
        "\n",
        "      self.model = nn.ModuleList()\n",
        "\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = input_channel_size, out_channels = NF * 2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "                     nn.ReLU())]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 2, out_channels = NF * 4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "                     nn.InstanceNorm2d(NF * 4, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 4, out_channels = NF * 8, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 8, out_channels = NF * 8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 8, out_channels = NF * 8, kernel_size = 3, stride = 1, padding = 2, dilation = 2, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 8, out_channels = NF * 8, kernel_size = 3, stride = 1, padding = 4, dilation = 4, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 8, out_channels = NF * 8, kernel_size = 3, stride = 1, padding = 8, dilation = 8, bias=False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 16, out_channels = NF * 8, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "                     nn.InstanceNorm2d(NF * 8, affine=True),\n",
        "                     nn.LeakyReLU(negative_slope = negative_slope))]\n",
        "      self.model += [nn.Sequential(nn.Conv2d(in_channels = NF * 8, out_channels = 1, kernel_size = 3, stride = 1, padding = 1, bias = False))]\n",
        "\n",
        "      for i in range(0, len(self.model)):\n",
        "        for j in range(0, len(self.model[i])):\n",
        "            self.model[i][j] = self.initializer(self.model[i][j])\n",
        "      \n",
        "    def forward(self, x):\n",
        "      feats = []\n",
        "      for i in range(0, len(self.model)):\n",
        "        if i != 0 and i != 1:\n",
        "          feats.append(x)\n",
        "        if i == 4:\n",
        "          a = x\n",
        "        if i == 7:\n",
        "          x = torch.cat((x, a), 1)\n",
        "        x = self.model[i](x)\n",
        "        #print(i)\n",
        "        #print(x)\n",
        "        #print(\"dis\", x.shape)\n",
        "\n",
        "      #print(\"==========\")\n",
        "\n",
        "      return x, feats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9yaTtrdY93S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANimorph(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GANimorph, self).__init__()\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "    self.store = Store()\n",
        "    if restore:\n",
        "      self.store_settings = self.store.restore_model()\n",
        "    else:\n",
        "      self.store_settings = self.store.make_store()\n",
        "\n",
        "    self.d_period = 1\n",
        "    self.g_period = 2\n",
        "\n",
        "    self.GAN_last_loss = 1\n",
        "    self.FM_last_loss = 1\n",
        "    self.CYC_last_loss = 1\n",
        "    self.L1_last_loss = 1\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid().cuda()\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "    self.real_labels = Variable(torch.full((16, 1, 16, 16), real_label)).cuda()\n",
        "    self.fake_labels = Variable(torch.full((16, 1, 16, 16), fake_label)).cuda()\n",
        "\n",
        "  def make_batch(self):\n",
        "    indexes_A = np.random.randint(len(files_A), size = minibatch_size)\n",
        "    indexes_B = np.random.randint(len(files_B), size = minibatch_size)\n",
        "\n",
        "    names_A = []\n",
        "    names_B = []\n",
        "    for i in range (0, minibatch_size):\n",
        "      names_A.append(files_A[indexes_A[i]])\n",
        "      names_B.append(files_B[indexes_B[i]])\n",
        "\n",
        "    batch_A = Variable(torch.FloatTensor(minibatch_size, 3, 128, 128)).cuda()\n",
        "    batch_B = Variable(torch.FloatTensor(minibatch_size, 3, 128, 128)).cuda()\n",
        "    for i in range(0, minibatch_size):\n",
        "      batch_A[i] = torch.transpose(torch.transpose(torch.from_numpy(np.array(Image.open(data_path_A + names_A[i]))), 1, 2), 0, 1)\n",
        "      batch_B[i] = torch.transpose(torch.transpose(torch.from_numpy(np.array(Image.open(data_path_B + names_B[i]))), 1, 2), 0, 1)\n",
        "\n",
        "    return batch_A, batch_B\n",
        "\n",
        "  def calculate_scheduled_GAN_loss(self, loss, iteration):\n",
        "    moving_average_loss = beta*self.GAN_last_loss + (1-beta)*loss\n",
        "    #print(moving_average_loss)\n",
        "    self.GAN_last_loss = moving_average_loss\n",
        "    if iteration % s == 0:\n",
        "      loss = loss / (moving_average_loss.item() + epsilon)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "  def calculate_scheduled_FM_loss(self, loss, iteration):\n",
        "    moving_average_loss = beta*self.FM_last_loss + (1-beta)*loss\n",
        "    self.FM_last_loss = moving_average_loss\n",
        "    if iteration % s == 0:\n",
        "      loss = loss / (moving_average_loss.item() + epsilon)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def calculate_scheduled_CYC_loss(self, loss, iteration):\n",
        "    moving_average_loss = beta*self.CYC_last_loss + (1-beta)*loss\n",
        "    self.CYC_last_loss = moving_average_loss\n",
        "    if iteration % s == 0:\n",
        "      loss = loss / (moving_average_loss.item() + epsilon)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def calculate_scheduled_L1_loss(self, loss, iteration):\n",
        "    moving_average_loss = beta*self.L1_last_loss + (1-beta)*loss\n",
        "    self.L1_last_loss = moving_average_loss\n",
        "    if iteration % s == 0:\n",
        "      loss = loss / (moving_average_loss.item() + epsilon)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def calculate_L1_loss(self, X, XYX, Y, YXY):\n",
        "    return (torch.mean(abs(XYX - X)) + torch.mean(abs(YXY - Y)))\n",
        "\n",
        "  def calculate_GAN_discriminator_loss(self, dis_real, dis_fake):\n",
        "    dis_real = self.sigmoid(dis_real)\n",
        "    dis_fake = self.sigmoid(dis_fake)\n",
        "\n",
        "    D_loss_real = self.criterion(dis_real, self.real_labels)\n",
        "    D_loss_fake = self.criterion(dis_fake, self.fake_labels)\n",
        "    D_loss = 0.5*(D_loss_real + D_loss_fake)\n",
        "\n",
        "    return D_loss\n",
        "\n",
        "  def calculate_GAN_generator_loss(self, dis_fake_for_gen):\n",
        "    dis_fake_for_gen = self.sigmoid(dis_fake_for_gen)\n",
        "\n",
        "    G_loss = self.criterion(dis_fake_for_gen, self.real_labels)\n",
        "\n",
        "    return G_loss\n",
        "\n",
        "  def calculate_feature_match_loss(self, feats_real, feats_fake):\n",
        "    losses = Variable(torch.FloatTensor(7, 16, 16)).cuda()\n",
        "    for i in range(0, len(feats_real)):\n",
        "      loss = torch.mean((torch.mean(feats_real[i], 0) - torch.mean(feats_fake[i], 0))**2)\n",
        "      losses[i] = loss\n",
        "    \n",
        "    result = torch.mean(losses)\n",
        "\n",
        "    return result\n",
        "\n",
        "  def pytorch_fspecial_gauss(self, size, sigma):\n",
        "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "    \"\"\"\n",
        "    x_data, y_data = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "\n",
        "    x_data = np.expand_dims(x_data, axis=-1)\n",
        "    x_data = torch.from_numpy(np.expand_dims(x_data, axis=-1))\n",
        "\n",
        "    y_data = np.expand_dims(y_data, axis=-1)\n",
        "    y_data = torch.from_numpy(np.expand_dims(y_data, axis=-1))\n",
        "\n",
        "    g = torch.exp(-((x_data**2 + y_data**2)/(2.0*sigma**2)))\n",
        "\n",
        "    return g / torch.sum(g)\n",
        "\n",
        "  def calculate_SSIM_loss(self, img1, img2, cs_map=False, mean_metric=True, size=8, sigma=1.5, l = 0):\n",
        "    window = self.pytorch_fspecial_gauss(size, sigma) # window shape [size, size]\n",
        "    window = torch.transpose(torch.transpose(window, 1, 3), 0, 2)\n",
        "    K1 = 0.03\n",
        "    K2 = 0.05\n",
        "    L = 1  # depth of image (255 in case the image has a differnt scale)\n",
        "    C1 = (K1*L)**2\n",
        "    C2 = (K2*L)**2\n",
        "    #mu1 = torch.FloatTensor(, requires_grad = True)\n",
        "    mu1 = F.conv2d(img1.cpu(), window)\n",
        "    mu2 = F.conv2d(img2.cpu(), window)\n",
        "    #window = window.cuda()\n",
        "    # mu1 = F.conv2d(img1, window)\n",
        "    # mu2 = F.conv2d(img2, window)\n",
        "\n",
        "    mu1_sq = mu1*mu1\n",
        "    mu2_sq = mu2*mu2\n",
        "    mu1_mu2 = mu1*mu2\n",
        "    sigma1_sq = F.conv2d((img1*img1).cpu(), window) - mu1_sq\n",
        "    sigma2_sq = F.conv2d((img2*img2).cpu(), window)  - mu2_sq\n",
        "    #print(F.conv2d((img1*img2), window).shape)\n",
        "    #print(mu1_mu2.shape)\n",
        "    sigma12 = F.conv2d((img1*img2).cpu(), window)  - mu1_mu2\n",
        "    # sigma1_sq = F.conv2d((img1*img1), window) - mu1_sq\n",
        "    # sigma2_sq = F.conv2d((img2*img2), window)  - mu2_sq\n",
        "    # sigma12 = F.conv2d((img1*img2), window)  - mu1_mu2\n",
        "    \n",
        "    sigma1_sq = abs(sigma1_sq)\n",
        "    sigma2_sq = abs(sigma2_sq)\n",
        "    sigma12 = abs(sigma12)\n",
        "    if cs_map:\n",
        "        value = (((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                    (sigma1_sq + sigma2_sq + C2)),\n",
        "                (2.0*sigma12 + C2)/(sigma1_sq + sigma2_sq + C2))\n",
        "    else:\n",
        "        value = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*\n",
        "                    (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if mean_metric:\n",
        "        value = torch.mean(value)\n",
        "        \n",
        "    return value\n",
        "\n",
        "  def calculate_MS_SSIM_loss(self, img1, img2, mean_metric=True, level=5):\n",
        "\n",
        "    weight = torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333])\n",
        "    mssim = []\n",
        "    mcs = []\n",
        "    for l in range(level):\n",
        "        ssim_map, cs_map = self.calculate_SSIM_loss(img1, img2, cs_map=True, mean_metric=False, l = 0)\n",
        "        mssim.append(torch.mean(torch.FloatTensor(ssim_map)))\n",
        "\n",
        "        mcs.append(torch.mean(torch.FloatTensor(cs_map)))\n",
        "        filtered_im1 = torch.nn.functional.avg_pool2d(img1, kernel_size = 2, stride = 2)\n",
        "        filtered_im2 = torch.nn.functional.avg_pool2d(img2, kernel_size = 2, stride = 2)\n",
        "        img1 = filtered_im1\n",
        "        img2 = filtered_im2\n",
        "\n",
        "    # list to tensor of dim D+1\n",
        "    mssim = torch.stack(mssim, axis=0)\n",
        "    mcs = torch.stack(mcs, axis=0)\n",
        "\n",
        "    value = (torch.prod(mcs[0:level-1]**weight[0:level-1])*\n",
        "                       (mssim[level-1]**weight[level-1])).cuda()\n",
        "\n",
        "    if mean_metric:\n",
        "        value = torch.mean(value)\n",
        "\n",
        "    return value\n",
        "\n",
        "  def calculate_DSSIM_loss(self, img1, img2):\n",
        "    img1 = img1.view(img1.shape[0], img1.shape[1], -1, img1.shape[2], img1.shape[3])\n",
        "    img2 = img2.view(img2.shape[0], img2.shape[1], -1, img2.shape[2], img2.shape[3])\n",
        "    img1 = torch.unbind(img1, axis=1)\n",
        "    img2 = torch.unbind(img2, axis=1)\n",
        "\n",
        "    value = torch.stack([self.calculate_MS_SSIM_loss(i1, i2) for i1, i2 in zip(img1, img2)], axis=0)\n",
        "\n",
        "    return (1.0 - torch.sum(value)/3)\n",
        "\n",
        "  def viz3(self, a, b, c, d, e, f, iteration):\n",
        "    im1 = torch.cat([a, b, c], axis=3)\n",
        "    im2 = torch.cat([d, e, f], axis=3)\n",
        "    im = torch.cat([im1, im2], axis=2)\n",
        "    im = torch.transpose(torch.transpose(im, 1, 2), 2, 3)\n",
        "    im = (im) * 255\n",
        "    im = torch.clamp(im, 0, 255)\n",
        "    im = im.type(torch.IntTensor)\n",
        "    #print(im)\n",
        "\n",
        "    imageio.imwrite(os.path.join(self.store_settings['samples_directory'], '%d.png' % (iteration)), im[0].numpy())\n",
        "\n",
        "  def train(self):\n",
        "    G1.cuda()\n",
        "    G2.cuda()\n",
        "    D1.cuda()\n",
        "    D2.cuda()\n",
        "\n",
        "    self.generator_optimizer = optim.Adam(itertools.chain(G1.parameters(), G2.parameters()), lr = learning_rate, betas = (beta1, beta2))\n",
        "    self.discriminator_optimizer = optim.Adam(itertools.chain(D1.parameters(), D2.parameters()), lr = learning_rate, betas = (beta1, beta2))\n",
        "\n",
        "    #for epoch in range(0, number_of_epoches):\n",
        "    for iteration in range(0, number_of_iterations):\n",
        "        A, B = self.make_batch()\n",
        "        A = A / 255.0\n",
        "        #print(A)\n",
        "        B = B / 255.0\n",
        "\n",
        "        AB = G1(A)\n",
        "        BA = G2(B)\n",
        "        ABA = G2(AB)\n",
        "        BAB = G1(BA)\n",
        "        \n",
        "        self.generator_optimizer.zero_grad()\n",
        "\n",
        "        _, A_feats_real = D1(A)\n",
        "        A_dis_fake_for_gen, A_feats_fake = D1(BA)\n",
        "\n",
        "        G_loss_A = self.calculate_GAN_generator_loss(A_dis_fake_for_gen)\n",
        "\n",
        "        recon_loss_A = self.calculate_DSSIM_loss(A, ABA)\n",
        "\n",
        "        fm_loss_A = self.calculate_feature_match_loss(A_feats_real, A_feats_fake)\n",
        "\n",
        "        _, B_feats_real = D2(B)\n",
        "        B_dis_fake_for_gen, B_feats_fake = D2(AB)\n",
        "\n",
        "        G_loss_B = self.calculate_GAN_generator_loss(B_dis_fake_for_gen)\n",
        "\n",
        "        recon_loss_B = self.calculate_DSSIM_loss(B, BAB)\n",
        "\n",
        "        fm_loss_B = self.calculate_feature_match_loss(B_feats_real, B_feats_fake)\n",
        "\n",
        "        recon_loss_l = self.calculate_L1_loss(A, ABA, B, BAB)\n",
        "\n",
        "        # g_loss = (self.calculate_scheduled_GAN_loss(G_loss_A + G_loss_B, iteration) * 0.7 + \\\n",
        "        #         self.calculate_scheduled_FM_loss(fm_loss_A + fm_loss_B, iteration) * 0.3) * (1 - rate)  + \\\n",
        "        #         (self.calculate_scheduled_CYC_loss((recon_loss_A + recon_loss_B), iteration) * 0.7 + \\\n",
        "        #         self.calculate_scheduled_L1_loss((recon_loss_l),iteration) * 0.3) * rate\n",
        "        g_loss = (self.calculate_scheduled_GAN_loss(G_loss_A + G_loss_B, iteration) * 0.7 + \\\n",
        "                self.calculate_scheduled_FM_loss(fm_loss_A + fm_loss_B, iteration) * 0.3) * (1 - rate)  + \\\n",
        "                (self.calculate_scheduled_CYC_loss((recon_loss_A + recon_loss_B), iteration) * 0.7 + \\\n",
        "                self.calculate_scheduled_L1_loss((recon_loss_l),iteration) * 0.3) * rate\n",
        "        print(iteration, \" g_loss\", g_loss.item())\n",
        "\n",
        "        g_loss.backward()\n",
        "\n",
        "        self.generator_optimizer.step()\n",
        "        \n",
        "        if iteration % 2 == 0:\n",
        "          self.discriminator_optimizer.zero_grad()\n",
        "\n",
        "        A_dis_real, _ = D1(A)\n",
        "        A_dis_fake, _ = D1(BA.detach())\n",
        "        D_loss_A  = self.calculate_GAN_discriminator_loss(A_dis_real, A_dis_fake)\n",
        "        \n",
        "        B_dis_real, B_feats_real = D2(B)\n",
        "        B_dis_fake, _ = D2(AB.detach())\n",
        "        D_loss_B  = self.calculate_GAN_discriminator_loss(B_dis_real, B_dis_fake)\n",
        "\n",
        "        d_loss = D_loss_A + D_loss_B\n",
        "        print(iteration, \" d_loss\", d_loss.item())\n",
        "        \n",
        "        if iteration % 2 == 0:\n",
        "          d_loss.backward()\n",
        "\n",
        "        self.discriminator_optimizer.step()\n",
        "\n",
        "        if iteration % freq == 0:\n",
        "          self.viz3(A, AB, ABA, B, BA, BAB, iteration)\n",
        "      \n",
        "        if iteration % 500 == 0 and iteration > 0:\n",
        "          g_file1 = os.path.join(self.store_settings['weights_directory'], '%s' % (str(iteration).zfill(6))) + '-G1.pth'\n",
        "          torch.save(G1.state_dict(), g_file1)\n",
        "          g_file2 = os.path.join(self.store_settings['weights_directory'], '%s' % (str(iteration).zfill(6))) + '-G2.pth'\n",
        "          torch.save(G1.state_dict(), g_file2)\n",
        "\n",
        "          d1_file = os.path.join(self.store_settings['weights_directory'], '%s' % (str(iteration).zfill(6))) + '-D1.pth'\n",
        "          torch.save(D1.state_dict(), d1_file)\n",
        "\n",
        "          d2_file = os.path.join(self.store_settings['weights_directory'], '%s' % (str(iteration).zfill(6))) + '-D2.pth'\n",
        "          torch.save(D2.state_dict(), d2_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRF37SXWroUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b28f5df-bdec-4d70-c2fb-13b400c8df15"
      },
      "source": [
        "learning_rate = 2e-4\n",
        "minibatch_size = 16\n",
        "\n",
        "beta1 = 0.95\n",
        "beta2 = 0.999\n",
        "\n",
        "beta = 0.9999\n",
        "epsilon = 1e-10\n",
        "s = 200\n",
        "\n",
        "freq = 100\n",
        "\n",
        "negative_slope = 0.2\n",
        "\n",
        "number_of_epoches = 150\n",
        "number_of_iterations = 150000\n",
        "\n",
        "lambda_gan = 0.49\n",
        "lambda_fm = 0.21\n",
        "lambda_cyc = 0.3\n",
        "lambda_ss = 0.70\n",
        "lambda_l1 = 0.3\n",
        "\n",
        "input_channel_size = 3\n",
        "NF = 64\n",
        "\n",
        "negative_slope = 0.2\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "rate = 0.33\n",
        "\n",
        "restore = False\n",
        "store_directory = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "data_path_A = \"/content/gdrive/My Drive/Colab Notebooks/cat_dog_face/cat_dog_face/trainA/\"\n",
        "data_path_B = \"/content/gdrive/My Drive/Colab Notebooks/cat_dog_face/cat_dog_face/trainB/\"\n",
        "\n",
        "files_A = [f for f in listdir(data_path_A) if isfile(join(data_path_A, f))]\n",
        "files_B = [f for f in listdir(data_path_B) if isfile(join(data_path_B, f))]\n",
        "\n",
        "G1 = Generator()\n",
        "print(G1)\n",
        "G2 = Generator()\n",
        "D1 = Discriminator()\n",
        "D2 = Discriminator()\n",
        "print(D1)\n",
        "GAN = GANimorph()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (initializer): Initializer()\n",
            "  (model): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (5): LeakyReLU(negative_slope=0.2)\n",
            "      (6): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (8): LeakyReLU(negative_slope=0.2)\n",
            "      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (11): LeakyReLU(negative_slope=0.2)\n",
            "      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (14): LeakyReLU(negative_slope=0.2)\n",
            "      (15): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (17): LeakyReLU(negative_slope=0.2)\n",
            "      (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (19): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (20): LeakyReLU(negative_slope=0.2)\n",
            "      (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (22): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (23): LeakyReLU(negative_slope=0.2)\n",
            "      (24): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (25): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (26): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (5): LeakyReLU(negative_slope=0.2)\n",
            "      (6): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (8): LeakyReLU(negative_slope=0.2)\n",
            "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (11): LeakyReLU(negative_slope=0.2)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (14): LeakyReLU(negative_slope=0.2)\n",
            "      (15): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (16): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (17): LeakyReLU(negative_slope=0.2)\n",
            "      (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (19): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (20): LeakyReLU(negative_slope=0.2)\n",
            "      (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (22): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (23): LeakyReLU(negative_slope=0.2)\n",
            "      (24): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (25): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (26): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (5): LeakyReLU(negative_slope=0.2)\n",
            "      (6): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (8): LeakyReLU(negative_slope=0.2)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (11): LeakyReLU(negative_slope=0.2)\n",
            "      (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (14): LeakyReLU(negative_slope=0.2)\n",
            "      (15): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (16): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (17): LeakyReLU(negative_slope=0.2)\n",
            "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (19): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (20): LeakyReLU(negative_slope=0.2)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (22): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (23): LeakyReLU(negative_slope=0.2)\n",
            "      (24): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (25): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (26): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (8): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (5): LeakyReLU(negative_slope=0.2)\n",
            "      (6): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (8): LeakyReLU(negative_slope=0.2)\n",
            "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (11): LeakyReLU(negative_slope=0.2)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (14): LeakyReLU(negative_slope=0.2)\n",
            "      (15): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (16): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (17): LeakyReLU(negative_slope=0.2)\n",
            "      (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (19): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (20): LeakyReLU(negative_slope=0.2)\n",
            "      (21): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (22): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (23): LeakyReLU(negative_slope=0.2)\n",
            "      (24): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (25): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (26): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (9): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (10): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (5): LeakyReLU(negative_slope=0.2)\n",
            "      (6): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (8): LeakyReLU(negative_slope=0.2)\n",
            "      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (11): LeakyReLU(negative_slope=0.2)\n",
            "      (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (13): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (14): LeakyReLU(negative_slope=0.2)\n",
            "      (15): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (17): LeakyReLU(negative_slope=0.2)\n",
            "      (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (19): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (20): LeakyReLU(negative_slope=0.2)\n",
            "      (21): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (22): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (23): LeakyReLU(negative_slope=0.2)\n",
            "      (24): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (25): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (26): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (11): Sequential(\n",
            "      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (12): Sequential(\n",
            "      (0): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Discriminator(\n",
            "  (initializer): Initializer()\n",
            "  (model): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (8): Sequential(\n",
            "      (0): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzPI99eEkvCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99c84f83-e831-4713-bc0f-86cb9934eb63"
      },
      "source": [
        "GAN.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  g_loss 0.9993885159492493\n",
            "0  d_loss 1.4367892742156982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1  g_loss 1.6410890817642212\n",
            "1  d_loss 2.0186209678649902\n",
            "2  g_loss 1.285774827003479\n",
            "2  d_loss 1.6933786869049072\n",
            "3  g_loss 1.1092331409454346\n",
            "3  d_loss 1.5622360706329346\n",
            "4  g_loss 1.0447908639907837\n",
            "4  d_loss 1.842872142791748\n",
            "5  g_loss 0.9269403219223022\n",
            "5  d_loss 1.6180064678192139\n",
            "6  g_loss 0.9380228519439697\n",
            "6  d_loss 1.975632905960083\n",
            "7  g_loss 0.8771974444389343\n",
            "7  d_loss 1.7196929454803467\n",
            "8  g_loss 0.8689675331115723\n",
            "8  d_loss 1.7146685123443604\n",
            "9  g_loss 0.859859049320221\n",
            "9  d_loss 1.5997593402862549\n",
            "10  g_loss 0.9024825096130371\n",
            "10  d_loss 1.5883815288543701\n",
            "11  g_loss 0.9179650545120239\n",
            "11  d_loss 1.5458338260650635\n",
            "12  g_loss 0.9078595638275146\n",
            "12  d_loss 1.4635419845581055\n",
            "13  g_loss 0.8920004367828369\n",
            "13  d_loss 1.4276866912841797\n",
            "14  g_loss 0.9214564561843872\n",
            "14  d_loss 1.4190531969070435\n",
            "15  g_loss 0.9292880296707153\n",
            "15  d_loss 1.4028412103652954\n",
            "16  g_loss 0.953708291053772\n",
            "16  d_loss 1.3789482116699219\n",
            "17  g_loss 0.9508684873580933\n",
            "17  d_loss 1.3783705234527588\n",
            "18  g_loss 0.9559365510940552\n",
            "18  d_loss 1.3758807182312012\n",
            "19  g_loss 0.9511425495147705\n",
            "19  d_loss 1.3682188987731934\n",
            "20  g_loss 0.9358333945274353\n",
            "20  d_loss 1.3623621463775635\n",
            "21  g_loss 0.9396515488624573\n",
            "21  d_loss 1.358396053314209\n",
            "22  g_loss 0.9162482023239136\n",
            "22  d_loss 1.3554233312606812\n",
            "23  g_loss 0.9084793329238892\n",
            "23  d_loss 1.357844352722168\n",
            "24  g_loss 0.8959090113639832\n",
            "24  d_loss 1.3587191104888916\n",
            "25  g_loss 0.8872928619384766\n",
            "25  d_loss 1.362133502960205\n",
            "26  g_loss 0.8634734153747559\n",
            "26  d_loss 1.3539023399353027\n",
            "27  g_loss 0.8575052618980408\n",
            "27  d_loss 1.3514785766601562\n",
            "28  g_loss 0.8512193560600281\n",
            "28  d_loss 1.3695474863052368\n",
            "29  g_loss 0.8437557220458984\n",
            "29  d_loss 1.3660962581634521\n",
            "30  g_loss 0.8403708934783936\n",
            "30  d_loss 1.3567490577697754\n",
            "31  g_loss 0.8416005373001099\n",
            "31  d_loss 1.340394377708435\n",
            "32  g_loss 0.8217631578445435\n",
            "32  d_loss 1.3457598686218262\n",
            "33  g_loss 0.832222580909729\n",
            "33  d_loss 1.3426913022994995\n",
            "34  g_loss 0.830348789691925\n",
            "34  d_loss 1.3320531845092773\n",
            "35  g_loss 0.8191468119621277\n",
            "35  d_loss 1.3328434228897095\n",
            "36  g_loss 0.8154404759407043\n",
            "36  d_loss 1.324497938156128\n",
            "37  g_loss 0.8348580598831177\n",
            "37  d_loss 1.303069829940796\n",
            "38  g_loss 0.8201545476913452\n",
            "38  d_loss 1.3132036924362183\n",
            "39  g_loss 0.8267441987991333\n",
            "39  d_loss 1.3131036758422852\n",
            "40  g_loss 0.8182679414749146\n",
            "40  d_loss 1.3223109245300293\n",
            "41  g_loss 0.8290339708328247\n",
            "41  d_loss 1.3218737840652466\n",
            "42  g_loss 0.8377285003662109\n",
            "42  d_loss 1.3032512664794922\n",
            "43  g_loss 0.8645931482315063\n",
            "43  d_loss 1.2841211557388306\n",
            "44  g_loss 0.8824581503868103\n",
            "44  d_loss 1.2706079483032227\n",
            "45  g_loss 0.89911288022995\n",
            "45  d_loss 1.2787094116210938\n",
            "46  g_loss 0.9147588610649109\n",
            "46  d_loss 1.2354639768600464\n",
            "47  g_loss 0.9338171482086182\n",
            "47  d_loss 1.24420166015625\n",
            "48  g_loss 0.9239161014556885\n",
            "48  d_loss 1.221914291381836\n",
            "49  g_loss 0.9408546090126038\n",
            "49  d_loss 1.2143619060516357\n",
            "50  g_loss 0.9152976274490356\n",
            "50  d_loss 1.209221363067627\n",
            "51  g_loss 0.9185805320739746\n",
            "51  d_loss 1.1825568675994873\n",
            "52  g_loss 0.9076063632965088\n",
            "52  d_loss 1.1804190874099731\n",
            "53  g_loss 0.9105318784713745\n",
            "53  d_loss 1.1784871816635132\n",
            "54  g_loss 0.9083027839660645\n",
            "54  d_loss 1.1737611293792725\n",
            "55  g_loss 0.9305166602134705\n",
            "55  d_loss 1.1409413814544678\n",
            "56  g_loss 0.9175570011138916\n",
            "56  d_loss 1.1711089611053467\n",
            "57  g_loss 0.9200681447982788\n",
            "57  d_loss 1.1474971771240234\n",
            "58  g_loss 0.9174126982688904\n",
            "58  d_loss 1.142859935760498\n",
            "59  g_loss 0.9034284353256226\n",
            "59  d_loss 1.1429158449172974\n",
            "60  g_loss 0.8537139892578125\n",
            "60  d_loss 1.194777011871338\n",
            "61  g_loss 0.8692295551300049\n",
            "61  d_loss 1.2095069885253906\n",
            "62  g_loss 0.8631545305252075\n",
            "62  d_loss 1.1808767318725586\n",
            "63  g_loss 0.8976966738700867\n",
            "63  d_loss 1.1797573566436768\n",
            "64  g_loss 0.9216024875640869\n",
            "64  d_loss 1.1733630895614624\n",
            "65  g_loss 0.9529183506965637\n",
            "65  d_loss 1.1713178157806396\n",
            "66  g_loss 0.9650455117225647\n",
            "66  d_loss 1.1553481817245483\n",
            "67  g_loss 0.9911102056503296\n",
            "67  d_loss 1.1571252346038818\n",
            "68  g_loss 0.9830123782157898\n",
            "68  d_loss 1.140832781791687\n",
            "69  g_loss 0.9946160316467285\n",
            "69  d_loss 1.1045384407043457\n",
            "70  g_loss 0.9688944816589355\n",
            "70  d_loss 1.1060822010040283\n",
            "71  g_loss 0.9612815380096436\n",
            "71  d_loss 1.088179111480713\n",
            "72  g_loss 0.9217472076416016\n",
            "72  d_loss 1.1245853900909424\n",
            "73  g_loss 0.9708263874053955\n",
            "73  d_loss 1.0696851015090942\n",
            "74  g_loss 0.9719140529632568\n",
            "74  d_loss 1.0809414386749268\n",
            "75  g_loss 1.0181498527526855\n",
            "75  d_loss 1.0593464374542236\n",
            "76  g_loss 1.0217955112457275\n",
            "76  d_loss 1.0062705278396606\n",
            "77  g_loss 1.048753261566162\n",
            "77  d_loss 0.9755622148513794\n",
            "78  g_loss 1.042070984840393\n",
            "78  d_loss 0.991436243057251\n",
            "79  g_loss 1.0575220584869385\n",
            "79  d_loss 1.037987232208252\n",
            "80  g_loss 1.034583330154419\n",
            "80  d_loss 1.0696450471878052\n",
            "81  g_loss 1.055161476135254\n",
            "81  d_loss 1.0567395687103271\n",
            "82  g_loss 0.9960176944732666\n",
            "82  d_loss 1.0972599983215332\n",
            "83  g_loss 0.9953826069831848\n",
            "83  d_loss 1.0851466655731201\n",
            "84  g_loss 0.8953297138214111\n",
            "84  d_loss 1.1999430656433105\n",
            "85  g_loss 0.8947333693504333\n",
            "85  d_loss 1.2696833610534668\n",
            "86  g_loss 0.8818509578704834\n",
            "86  d_loss 1.3244643211364746\n",
            "87  g_loss 0.949978232383728\n",
            "87  d_loss 1.2923930883407593\n",
            "88  g_loss 0.9940135478973389\n",
            "88  d_loss 1.1993556022644043\n",
            "89  g_loss 1.0237209796905518\n",
            "89  d_loss 1.2963275909423828\n",
            "90  g_loss 0.997045636177063\n",
            "90  d_loss 1.2693517208099365\n",
            "91  g_loss 0.9804307818412781\n",
            "91  d_loss 1.303849220275879\n",
            "92  g_loss 0.9041136503219604\n",
            "92  d_loss 1.31279456615448\n",
            "93  g_loss 0.9017733335494995\n",
            "93  d_loss 1.3127644062042236\n",
            "94  g_loss 0.8843430876731873\n",
            "94  d_loss 1.2591642141342163\n",
            "95  g_loss 0.9031104445457458\n",
            "95  d_loss 1.2242335081100464\n",
            "96  g_loss 0.8891323804855347\n",
            "96  d_loss 1.228362798690796\n",
            "97  g_loss 0.9284188747406006\n",
            "97  d_loss 1.1779444217681885\n",
            "98  g_loss 0.928723156452179\n",
            "98  d_loss 1.1799283027648926\n",
            "99  g_loss 0.988240122795105\n",
            "99  d_loss 1.1403112411499023\n",
            "100  g_loss 0.9451272487640381\n",
            "100  d_loss 1.1587040424346924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "101  g_loss 0.9519901275634766\n",
            "101  d_loss 1.2124052047729492\n",
            "102  g_loss 0.9351452589035034\n",
            "102  d_loss 1.201958179473877\n",
            "103  g_loss 0.9478635191917419\n",
            "103  d_loss 1.1678481101989746\n",
            "104  g_loss 0.9402936100959778\n",
            "104  d_loss 1.161047101020813\n",
            "105  g_loss 0.9275811910629272\n",
            "105  d_loss 1.232434630393982\n",
            "106  g_loss 0.8774231672286987\n",
            "106  d_loss 1.2607792615890503\n",
            "107  g_loss 0.9208969473838806\n",
            "107  d_loss 1.1953434944152832\n",
            "108  g_loss 0.8723577857017517\n",
            "108  d_loss 1.2786520719528198\n",
            "109  g_loss 0.8489018082618713\n",
            "109  d_loss 1.3289191722869873\n",
            "110  g_loss 0.8018914461135864\n",
            "110  d_loss 1.3361005783081055\n",
            "111  g_loss 0.8418487310409546\n",
            "111  d_loss 1.358597755432129\n",
            "112  g_loss 0.8685532212257385\n",
            "112  d_loss 1.3287553787231445\n",
            "113  g_loss 0.9093838930130005\n",
            "113  d_loss 1.3834452629089355\n",
            "114  g_loss 0.9018370509147644\n",
            "114  d_loss 1.41756272315979\n",
            "115  g_loss 0.915449321269989\n",
            "115  d_loss 1.3977108001708984\n",
            "116  g_loss 0.8863747715950012\n",
            "116  d_loss 1.4397461414337158\n",
            "117  g_loss 0.9142835140228271\n",
            "117  d_loss 1.348562240600586\n",
            "118  g_loss 0.8931505680084229\n",
            "118  d_loss 1.4091029167175293\n",
            "119  g_loss 0.8961898684501648\n",
            "119  d_loss 1.3238246440887451\n",
            "120  g_loss 0.8452765941619873\n",
            "120  d_loss 1.3664249181747437\n",
            "121  g_loss 0.8483796715736389\n",
            "121  d_loss 1.3291126489639282\n",
            "122  g_loss 0.808692216873169\n",
            "122  d_loss 1.3568713665008545\n",
            "123  g_loss 0.7933571338653564\n",
            "123  d_loss 1.3654038906097412\n",
            "124  g_loss 0.8065235614776611\n",
            "124  d_loss 1.3687796592712402\n",
            "125  g_loss 0.8015309572219849\n",
            "125  d_loss 1.3587837219238281\n",
            "126  g_loss 0.7757241129875183\n",
            "126  d_loss 1.3360847234725952\n",
            "127  g_loss 0.7531288266181946\n",
            "127  d_loss 1.3970494270324707\n",
            "128  g_loss 0.7378767132759094\n",
            "128  d_loss 1.362061619758606\n",
            "129  g_loss 0.7529460787773132\n",
            "129  d_loss 1.374236822128296\n",
            "130  g_loss 0.768217146396637\n",
            "130  d_loss 1.3602221012115479\n",
            "131  g_loss 0.7976760864257812\n",
            "131  d_loss 1.3522381782531738\n",
            "132  g_loss 0.7881564497947693\n",
            "132  d_loss 1.3673312664031982\n",
            "133  g_loss 0.8189882636070251\n",
            "133  d_loss 1.339873194694519\n",
            "134  g_loss 0.7972972989082336\n",
            "134  d_loss 1.3401944637298584\n",
            "135  g_loss 0.7906099557876587\n",
            "135  d_loss 1.3862078189849854\n",
            "136  g_loss 0.8004368543624878\n",
            "136  d_loss 1.3591594696044922\n",
            "137  g_loss 0.7809613347053528\n",
            "137  d_loss 1.3703211545944214\n",
            "138  g_loss 0.7716678380966187\n",
            "138  d_loss 1.3824846744537354\n",
            "139  g_loss 0.7703614234924316\n",
            "139  d_loss 1.3595325946807861\n",
            "140  g_loss 0.7615944743156433\n",
            "140  d_loss 1.3304235935211182\n",
            "141  g_loss 0.7692075967788696\n",
            "141  d_loss 1.3586286306381226\n",
            "142  g_loss 0.7490633726119995\n",
            "142  d_loss 1.407275676727295\n",
            "143  g_loss 0.7417121529579163\n",
            "143  d_loss 1.3964706659317017\n",
            "144  g_loss 0.7405393719673157\n",
            "144  d_loss 1.4013653993606567\n",
            "145  g_loss 0.7566869258880615\n",
            "145  d_loss 1.4263474941253662\n",
            "146  g_loss 0.7561953663825989\n",
            "146  d_loss 1.4142159223556519\n",
            "147  g_loss 0.7677278518676758\n",
            "147  d_loss 1.3999578952789307\n",
            "148  g_loss 0.7597277164459229\n",
            "148  d_loss 1.3883676528930664\n",
            "149  g_loss 0.8071850538253784\n",
            "149  d_loss 1.3486833572387695\n",
            "150  g_loss 0.7923239469528198\n",
            "150  d_loss 1.356194257736206\n",
            "151  g_loss 0.7972214818000793\n",
            "151  d_loss 1.3438528776168823\n",
            "152  g_loss 0.8105624318122864\n",
            "152  d_loss 1.3673670291900635\n",
            "153  g_loss 0.8133969902992249\n",
            "153  d_loss 1.3267052173614502\n",
            "154  g_loss 0.8033945560455322\n",
            "154  d_loss 1.3313758373260498\n",
            "155  g_loss 0.7944239377975464\n",
            "155  d_loss 1.3053834438323975\n",
            "156  g_loss 0.7977558374404907\n",
            "156  d_loss 1.2925041913986206\n",
            "157  g_loss 0.8001805543899536\n",
            "157  d_loss 1.314213514328003\n",
            "158  g_loss 0.7781007289886475\n",
            "158  d_loss 1.3025555610656738\n",
            "159  g_loss 0.7895910739898682\n",
            "159  d_loss 1.28916597366333\n",
            "160  g_loss 0.7750534415245056\n",
            "160  d_loss 1.2706072330474854\n",
            "161  g_loss 0.7727832198143005\n",
            "161  d_loss 1.3055390119552612\n",
            "162  g_loss 0.7850617170333862\n",
            "162  d_loss 1.2609868049621582\n",
            "163  g_loss 0.8072458505630493\n",
            "163  d_loss 1.2334349155426025\n",
            "164  g_loss 0.7911199331283569\n",
            "164  d_loss 1.2530574798583984\n",
            "165  g_loss 0.8085924983024597\n",
            "165  d_loss 1.2787810564041138\n",
            "166  g_loss 0.7989470958709717\n",
            "166  d_loss 1.2154145240783691\n",
            "167  g_loss 0.8134730458259583\n",
            "167  d_loss 1.2008628845214844\n",
            "168  g_loss 0.789347767829895\n",
            "168  d_loss 1.2513699531555176\n",
            "169  g_loss 0.810795247554779\n",
            "169  d_loss 1.2703981399536133\n",
            "170  g_loss 0.7728853225708008\n",
            "170  d_loss 1.3016173839569092\n",
            "171  g_loss 0.8246591687202454\n",
            "171  d_loss 1.24442720413208\n",
            "172  g_loss 0.8044161796569824\n",
            "172  d_loss 1.247499942779541\n",
            "173  g_loss 0.8602508902549744\n",
            "173  d_loss 1.1842031478881836\n",
            "174  g_loss 0.8939220309257507\n",
            "174  d_loss 1.1735655069351196\n",
            "175  g_loss 0.9188054800033569\n",
            "175  d_loss 1.147092342376709\n",
            "176  g_loss 0.9303596615791321\n",
            "176  d_loss 1.1404271125793457\n",
            "177  g_loss 0.9532597064971924\n",
            "177  d_loss 1.1368038654327393\n",
            "178  g_loss 0.9201889038085938\n",
            "178  d_loss 1.128659963607788\n",
            "179  g_loss 0.9040404558181763\n",
            "179  d_loss 1.1862424612045288\n",
            "180  g_loss 0.8446343541145325\n",
            "180  d_loss 1.1622422933578491\n",
            "181  g_loss 0.8506193161010742\n",
            "181  d_loss 1.1526882648468018\n",
            "182  g_loss 0.7797832489013672\n",
            "182  d_loss 1.216271162033081\n",
            "183  g_loss 0.8566180467605591\n",
            "183  d_loss 1.1603765487670898\n",
            "184  g_loss 0.9086076021194458\n",
            "184  d_loss 1.192528247833252\n",
            "185  g_loss 0.90909743309021\n",
            "185  d_loss 1.2981704473495483\n",
            "186  g_loss 0.9141585230827332\n",
            "186  d_loss 1.2450871467590332\n",
            "187  g_loss 0.8969127535820007\n",
            "187  d_loss 1.1994099617004395\n",
            "188  g_loss 0.8424456119537354\n",
            "188  d_loss 1.1966729164123535\n",
            "189  g_loss 0.778188943862915\n",
            "189  d_loss 1.2269818782806396\n",
            "190  g_loss 0.6562791466712952\n",
            "190  d_loss 1.4089810848236084\n",
            "191  g_loss 0.7211311459541321\n",
            "191  d_loss 1.2972605228424072\n",
            "192  g_loss 0.8457598686218262\n",
            "192  d_loss 1.131401538848877\n",
            "193  g_loss 0.9145161509513855\n",
            "193  d_loss 1.131678819656372\n",
            "194  g_loss 0.9482415318489075\n",
            "194  d_loss 1.138719916343689\n",
            "195  g_loss 0.9805209636688232\n",
            "195  d_loss 1.13748300075531\n",
            "196  g_loss 0.9808322191238403\n",
            "196  d_loss 1.1949310302734375\n",
            "197  g_loss 0.9733853340148926\n",
            "197  d_loss 1.1910991668701172\n",
            "198  g_loss 0.946701169013977\n",
            "198  d_loss 1.2326815128326416\n",
            "199  g_loss 0.9341825246810913\n",
            "199  d_loss 1.1624345779418945\n",
            "200  g_loss 0.872006893157959\n",
            "200  d_loss 1.1597676277160645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "201  g_loss 0.825435996055603\n",
            "201  d_loss 1.1813108921051025\n",
            "202  g_loss 0.7576178312301636\n",
            "202  d_loss 1.2314971685409546\n",
            "203  g_loss 0.6968289613723755\n",
            "203  d_loss 1.3181157112121582\n",
            "204  g_loss 0.6318624019622803\n",
            "204  d_loss 1.4572274684906006\n",
            "205  g_loss 0.6249956488609314\n",
            "205  d_loss 1.4812884330749512\n",
            "206  g_loss 0.6437456607818604\n",
            "206  d_loss 1.3859570026397705\n",
            "207  g_loss 0.7059550285339355\n",
            "207  d_loss 1.2985341548919678\n",
            "208  g_loss 0.7515849471092224\n",
            "208  d_loss 1.29058039188385\n",
            "209  g_loss 0.8002193570137024\n",
            "209  d_loss 1.2788782119750977\n",
            "210  g_loss 0.826686680316925\n",
            "210  d_loss 1.2428746223449707\n",
            "211  g_loss 0.851099967956543\n",
            "211  d_loss 1.3219034671783447\n",
            "212  g_loss 0.8879623413085938\n",
            "212  d_loss 1.2616240978240967\n",
            "213  g_loss 0.9283022284507751\n",
            "213  d_loss 1.3040094375610352\n",
            "214  g_loss 0.9287434816360474\n",
            "214  d_loss 1.3226079940795898\n",
            "215  g_loss 0.929886519908905\n",
            "215  d_loss 1.3062407970428467\n",
            "216  g_loss 0.8923872709274292\n",
            "216  d_loss 1.3240227699279785\n",
            "217  g_loss 0.8661600947380066\n",
            "217  d_loss 1.3696783781051636\n",
            "218  g_loss 0.8416730761528015\n",
            "218  d_loss 1.2886383533477783\n",
            "219  g_loss 0.8439432382583618\n",
            "219  d_loss 1.3178800344467163\n",
            "220  g_loss 0.8418387770652771\n",
            "220  d_loss 1.25133216381073\n",
            "221  g_loss 0.8407788872718811\n",
            "221  d_loss 1.2757222652435303\n",
            "222  g_loss 0.8323724269866943\n",
            "222  d_loss 1.295460820198059\n",
            "223  g_loss 0.8418682813644409\n",
            "223  d_loss 1.2154492139816284\n",
            "224  g_loss 0.8055161833763123\n",
            "224  d_loss 1.274769902229309\n",
            "225  g_loss 0.787256121635437\n",
            "225  d_loss 1.274597406387329\n",
            "226  g_loss 0.7380173802375793\n",
            "226  d_loss 1.2701352834701538\n",
            "227  g_loss 0.7621570825576782\n",
            "227  d_loss 1.2502679824829102\n",
            "228  g_loss 0.7241541147232056\n",
            "228  d_loss 1.2579505443572998\n",
            "229  g_loss 0.7427844405174255\n",
            "229  d_loss 1.2698345184326172\n",
            "230  g_loss 0.7455400228500366\n",
            "230  d_loss 1.228980541229248\n",
            "231  g_loss 0.8102339506149292\n",
            "231  d_loss 1.164426565170288\n",
            "232  g_loss 0.8245514035224915\n",
            "232  d_loss 1.1178758144378662\n",
            "233  g_loss 0.8672013282775879\n",
            "233  d_loss 1.1354951858520508\n",
            "234  g_loss 0.8914792537689209\n",
            "234  d_loss 1.0898239612579346\n",
            "235  g_loss 0.9047744274139404\n",
            "235  d_loss 1.0553714036941528\n",
            "236  g_loss 0.8934810161590576\n",
            "236  d_loss 1.0785763263702393\n",
            "237  g_loss 0.8963124752044678\n",
            "237  d_loss 1.0465389490127563\n",
            "238  g_loss 0.8393238186836243\n",
            "238  d_loss 1.106431245803833\n",
            "239  g_loss 0.8539367914199829\n",
            "239  d_loss 1.0805354118347168\n",
            "240  g_loss 0.8497101068496704\n",
            "240  d_loss 1.1119568347930908\n",
            "241  g_loss 0.8970476388931274\n",
            "241  d_loss 1.0536541938781738\n",
            "242  g_loss 0.9329298138618469\n",
            "242  d_loss 1.0009846687316895\n",
            "243  g_loss 1.0428119897842407\n",
            "243  d_loss 0.9812558889389038\n",
            "244  g_loss 1.0954898595809937\n",
            "244  d_loss 0.9212459921836853\n",
            "245  g_loss 1.1282331943511963\n",
            "245  d_loss 0.9218463897705078\n",
            "246  g_loss 1.124499797821045\n",
            "246  d_loss 0.8590053915977478\n",
            "247  g_loss 1.1771433353424072\n",
            "247  d_loss 0.8343424797058105\n",
            "248  g_loss 1.0853219032287598\n",
            "248  d_loss 0.8861256837844849\n",
            "249  g_loss 1.1070486307144165\n",
            "249  d_loss 0.8345993757247925\n",
            "250  g_loss 0.914702296257019\n",
            "250  d_loss 1.030257225036621\n",
            "251  g_loss 0.8751665353775024\n",
            "251  d_loss 1.0842201709747314\n",
            "252  g_loss 0.8096827268600464\n",
            "252  d_loss 1.2183876037597656\n",
            "253  g_loss 1.0066463947296143\n",
            "253  d_loss 0.9958048462867737\n",
            "254  g_loss 1.0575292110443115\n",
            "254  d_loss 1.088224172592163\n",
            "255  g_loss 1.1871416568756104\n",
            "255  d_loss 1.1354854106903076\n",
            "256  g_loss 1.1245416402816772\n",
            "256  d_loss 1.2191946506500244\n",
            "257  g_loss 1.1203551292419434\n",
            "257  d_loss 1.2649976015090942\n",
            "258  g_loss 1.0266873836517334\n",
            "258  d_loss 1.2370266914367676\n",
            "259  g_loss 1.032243251800537\n",
            "259  d_loss 1.221215009689331\n",
            "260  g_loss 0.987434983253479\n",
            "260  d_loss 1.2121913433074951\n",
            "261  g_loss 0.9566582441329956\n",
            "261  d_loss 1.2452690601348877\n",
            "262  g_loss 0.9051891565322876\n",
            "262  d_loss 1.2517688274383545\n",
            "263  g_loss 0.9140336513519287\n",
            "263  d_loss 1.158585548400879\n",
            "264  g_loss 0.884954571723938\n",
            "264  d_loss 1.1886637210845947\n",
            "265  g_loss 0.9012042284011841\n",
            "265  d_loss 1.1338880062103271\n",
            "266  g_loss 0.8653467893600464\n",
            "266  d_loss 1.172288179397583\n",
            "267  g_loss 0.9297887086868286\n",
            "267  d_loss 1.1161320209503174\n",
            "268  g_loss 0.8868788480758667\n",
            "268  d_loss 1.1537001132965088\n",
            "269  g_loss 0.9238486886024475\n",
            "269  d_loss 1.0656322240829468\n",
            "270  g_loss 0.930339515209198\n",
            "270  d_loss 1.0844695568084717\n",
            "271  g_loss 0.9786475300788879\n",
            "271  d_loss 1.015971302986145\n",
            "272  g_loss 0.9444621801376343\n",
            "272  d_loss 1.1038243770599365\n",
            "273  g_loss 0.9452391266822815\n",
            "273  d_loss 1.1344990730285645\n",
            "274  g_loss 0.9005885124206543\n",
            "274  d_loss 1.200713038444519\n",
            "275  g_loss 0.9153776168823242\n",
            "275  d_loss 1.273226022720337\n",
            "276  g_loss 0.8416330218315125\n",
            "276  d_loss 1.31422758102417\n",
            "277  g_loss 0.8724627494812012\n",
            "277  d_loss 1.2882344722747803\n",
            "278  g_loss 0.8301593065261841\n",
            "278  d_loss 1.3616505861282349\n",
            "279  g_loss 0.8776603937149048\n",
            "279  d_loss 1.3863747119903564\n",
            "280  g_loss 0.9309989809989929\n",
            "280  d_loss 1.4038634300231934\n",
            "281  g_loss 1.0034078359603882\n",
            "281  d_loss 1.3571704626083374\n",
            "282  g_loss 0.9924626350402832\n",
            "282  d_loss 1.4262990951538086\n",
            "283  g_loss 1.0029301643371582\n",
            "283  d_loss 1.4086065292358398\n",
            "284  g_loss 0.9614533185958862\n",
            "284  d_loss 1.4161394834518433\n",
            "285  g_loss 0.9197969436645508\n",
            "285  d_loss 1.397167444229126\n",
            "286  g_loss 0.7871910333633423\n",
            "286  d_loss 1.511441946029663\n",
            "287  g_loss 0.7802211046218872\n",
            "287  d_loss 1.5319998264312744\n",
            "288  g_loss 0.85527503490448\n",
            "288  d_loss 1.4088057279586792\n",
            "289  g_loss 0.9254429340362549\n",
            "289  d_loss 1.4053313732147217\n",
            "290  g_loss 0.9674712419509888\n",
            "290  d_loss 1.3866745233535767\n",
            "291  g_loss 0.9933191537857056\n",
            "291  d_loss 1.411816954612732\n",
            "292  g_loss 0.9713889360427856\n",
            "292  d_loss 1.389177680015564\n",
            "293  g_loss 0.9754124879837036\n",
            "293  d_loss 1.4188730716705322\n",
            "294  g_loss 0.9508322477340698\n",
            "294  d_loss 1.310919165611267\n",
            "295  g_loss 0.9389711618423462\n",
            "295  d_loss 1.28424870967865\n",
            "296  g_loss 0.907461404800415\n",
            "296  d_loss 1.2463500499725342\n",
            "297  g_loss 0.8387778997421265\n",
            "297  d_loss 1.334153413772583\n",
            "298  g_loss 0.7177360653877258\n",
            "298  d_loss 1.604076623916626\n",
            "299  g_loss 0.7498531341552734\n",
            "299  d_loss 1.515541672706604\n",
            "300  g_loss 0.7909208536148071\n",
            "300  d_loss 1.3823535442352295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "301  g_loss 0.8451089859008789\n",
            "301  d_loss 1.2807040214538574\n",
            "302  g_loss 0.8921597003936768\n",
            "302  d_loss 1.2527170181274414\n",
            "303  g_loss 0.9175256490707397\n",
            "303  d_loss 1.2268917560577393\n",
            "304  g_loss 0.9038141965866089\n",
            "304  d_loss 1.2507777214050293\n",
            "305  g_loss 0.9248878955841064\n",
            "305  d_loss 1.259894847869873\n",
            "306  g_loss 0.9020220041275024\n",
            "306  d_loss 1.3099119663238525\n",
            "307  g_loss 0.8935126662254333\n",
            "307  d_loss 1.2853219509124756\n",
            "308  g_loss 0.8977693319320679\n",
            "308  d_loss 1.2441339492797852\n",
            "309  g_loss 0.8599498271942139\n",
            "309  d_loss 1.3083207607269287\n",
            "310  g_loss 0.8493108749389648\n",
            "310  d_loss 1.3030409812927246\n",
            "311  g_loss 0.8330950140953064\n",
            "311  d_loss 1.3268790245056152\n",
            "312  g_loss 0.7775962352752686\n",
            "312  d_loss 1.3735175132751465\n",
            "313  g_loss 0.7680667638778687\n",
            "313  d_loss 1.364845871925354\n",
            "314  g_loss 0.6920194029808044\n",
            "314  d_loss 1.5678281784057617\n",
            "315  g_loss 0.6866662502288818\n",
            "315  d_loss 1.6514651775360107\n",
            "316  g_loss 0.6847243309020996\n",
            "316  d_loss 1.6392414569854736\n",
            "317  g_loss 0.6980516314506531\n",
            "317  d_loss 1.5952987670898438\n",
            "318  g_loss 0.7096533179283142\n",
            "318  d_loss 1.5282418727874756\n",
            "319  g_loss 0.7317720055580139\n",
            "319  d_loss 1.4839235544204712\n",
            "320  g_loss 0.7858314514160156\n",
            "320  d_loss 1.4327259063720703\n",
            "321  g_loss 0.8115567564964294\n",
            "321  d_loss 1.3962029218673706\n",
            "322  g_loss 0.8637640476226807\n",
            "322  d_loss 1.3628284931182861\n",
            "323  g_loss 0.9030889272689819\n",
            "323  d_loss 1.2838082313537598\n",
            "324  g_loss 0.920515775680542\n",
            "324  d_loss 1.2855572700500488\n",
            "325  g_loss 0.9726760983467102\n",
            "325  d_loss 1.2393476963043213\n",
            "326  g_loss 0.9439324140548706\n",
            "326  d_loss 1.2466671466827393\n",
            "327  g_loss 0.9546348452568054\n",
            "327  d_loss 1.2375212907791138\n",
            "328  g_loss 0.966907262802124\n",
            "328  d_loss 1.232338547706604\n",
            "329  g_loss 0.9692869186401367\n",
            "329  d_loss 1.202698826789856\n",
            "330  g_loss 0.9372811317443848\n",
            "330  d_loss 1.2065706253051758\n",
            "331  g_loss 0.9204160571098328\n",
            "331  d_loss 1.195444107055664\n",
            "332  g_loss 0.9167336225509644\n",
            "332  d_loss 1.207554817199707\n",
            "333  g_loss 0.889870285987854\n",
            "333  d_loss 1.2076983451843262\n",
            "334  g_loss 0.8734397292137146\n",
            "334  d_loss 1.2302933931350708\n",
            "335  g_loss 0.8564967513084412\n",
            "335  d_loss 1.214752197265625\n",
            "336  g_loss 0.8455414772033691\n",
            "336  d_loss 1.1970088481903076\n",
            "337  g_loss 0.8316550850868225\n",
            "337  d_loss 1.2114442586898804\n",
            "338  g_loss 0.828533947467804\n",
            "338  d_loss 1.2036347389221191\n",
            "339  g_loss 0.8360263109207153\n",
            "339  d_loss 1.206176519393921\n",
            "340  g_loss 0.8180190920829773\n",
            "340  d_loss 1.2346701622009277\n",
            "341  g_loss 0.8288601636886597\n",
            "341  d_loss 1.2097678184509277\n",
            "342  g_loss 0.8254131078720093\n",
            "342  d_loss 1.2039494514465332\n",
            "343  g_loss 0.8437235951423645\n",
            "343  d_loss 1.1905107498168945\n",
            "344  g_loss 0.8732127547264099\n",
            "344  d_loss 1.166823148727417\n",
            "345  g_loss 0.8904417157173157\n",
            "345  d_loss 1.1931016445159912\n",
            "346  g_loss 0.9240940809249878\n",
            "346  d_loss 1.1892257928848267\n",
            "347  g_loss 0.9487189650535583\n",
            "347  d_loss 1.1165372133255005\n",
            "348  g_loss 0.9187917113304138\n",
            "348  d_loss 1.164719581604004\n",
            "349  g_loss 0.9618222713470459\n",
            "349  d_loss 1.065034031867981\n",
            "350  g_loss 0.8919007778167725\n",
            "350  d_loss 1.1136524677276611\n",
            "351  g_loss 0.933730959892273\n",
            "351  d_loss 1.0819203853607178\n",
            "352  g_loss 0.9149674773216248\n",
            "352  d_loss 1.1014224290847778\n",
            "353  g_loss 0.9208720922470093\n",
            "353  d_loss 1.1287689208984375\n",
            "354  g_loss 0.8571832180023193\n",
            "354  d_loss 1.186635971069336\n",
            "355  g_loss 0.9448337554931641\n",
            "355  d_loss 1.123038411140442\n",
            "356  g_loss 0.9284671545028687\n",
            "356  d_loss 1.156935214996338\n",
            "357  g_loss 0.9827431440353394\n",
            "357  d_loss 1.058909296989441\n",
            "358  g_loss 0.9706153273582458\n",
            "358  d_loss 1.0786879062652588\n",
            "359  g_loss 0.9638189673423767\n",
            "359  d_loss 1.105074167251587\n",
            "360  g_loss 0.9507188200950623\n",
            "360  d_loss 1.0625638961791992\n",
            "361  g_loss 0.9267348051071167\n",
            "361  d_loss 1.1111729145050049\n",
            "362  g_loss 0.8489143252372742\n",
            "362  d_loss 1.16383695602417\n",
            "363  g_loss 0.9107260704040527\n",
            "363  d_loss 1.1117078065872192\n",
            "364  g_loss 0.954111635684967\n",
            "364  d_loss 1.1318206787109375\n",
            "365  g_loss 0.9667453169822693\n",
            "365  d_loss 1.1076327562332153\n",
            "366  g_loss 0.9501526355743408\n",
            "366  d_loss 1.1053980588912964\n",
            "367  g_loss 0.9416698813438416\n",
            "367  d_loss 1.0637788772583008\n",
            "368  g_loss 0.9166642427444458\n",
            "368  d_loss 1.0477038621902466\n",
            "369  g_loss 0.8669348955154419\n",
            "369  d_loss 1.0993423461914062\n",
            "370  g_loss 0.7701913714408875\n",
            "370  d_loss 1.218102216720581\n",
            "371  g_loss 0.7858179211616516\n",
            "371  d_loss 1.1761152744293213\n",
            "372  g_loss 0.8680188059806824\n",
            "372  d_loss 1.109158992767334\n",
            "373  g_loss 0.9161690473556519\n",
            "373  d_loss 1.1411995887756348\n",
            "374  g_loss 0.9723482131958008\n",
            "374  d_loss 1.160107135772705\n",
            "375  g_loss 0.9829932451248169\n",
            "375  d_loss 1.1639430522918701\n",
            "376  g_loss 0.9738474488258362\n",
            "376  d_loss 1.2072656154632568\n",
            "377  g_loss 0.981742799282074\n",
            "377  d_loss 1.209277629852295\n",
            "378  g_loss 0.931808352470398\n",
            "378  d_loss 1.199130654335022\n",
            "379  g_loss 0.9120571613311768\n",
            "379  d_loss 1.116171956062317\n",
            "380  g_loss 0.8493881225585938\n",
            "380  d_loss 1.1424109935760498\n",
            "381  g_loss 0.8018495440483093\n",
            "381  d_loss 1.1694679260253906\n",
            "382  g_loss 0.678291380405426\n",
            "382  d_loss 1.323313593864441\n",
            "383  g_loss 0.6567355394363403\n",
            "383  d_loss 1.478583812713623\n",
            "384  g_loss 0.6308168172836304\n",
            "384  d_loss 1.5955802202224731\n",
            "385  g_loss 0.7186555862426758\n",
            "385  d_loss 1.38010835647583\n",
            "386  g_loss 0.8135718703269958\n",
            "386  d_loss 1.1972906589508057\n",
            "387  g_loss 0.8849728107452393\n",
            "387  d_loss 1.2254714965820312\n",
            "388  g_loss 0.954561173915863\n",
            "388  d_loss 1.1640944480895996\n",
            "389  g_loss 0.9845542311668396\n",
            "389  d_loss 1.2153828144073486\n",
            "390  g_loss 1.0297611951828003\n",
            "390  d_loss 1.2344427108764648\n",
            "391  g_loss 1.0162895917892456\n",
            "391  d_loss 1.2791717052459717\n",
            "392  g_loss 0.9860485196113586\n",
            "392  d_loss 1.2790884971618652\n",
            "393  g_loss 0.9779641628265381\n",
            "393  d_loss 1.2634000778198242\n",
            "394  g_loss 0.9306914806365967\n",
            "394  d_loss 1.2802858352661133\n",
            "395  g_loss 0.907055675983429\n",
            "395  d_loss 1.2464113235473633\n",
            "396  g_loss 0.8557084798812866\n",
            "396  d_loss 1.2566125392913818\n",
            "397  g_loss 0.8372882604598999\n",
            "397  d_loss 1.2303378582000732\n",
            "398  g_loss 0.7917799353599548\n",
            "398  d_loss 1.2223507165908813\n",
            "399  g_loss 0.7625499367713928\n",
            "399  d_loss 1.2768473625183105\n",
            "400  g_loss 0.7551077604293823\n",
            "400  d_loss 1.2413086891174316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "401  g_loss 0.7237588763237\n",
            "401  d_loss 1.2967281341552734\n",
            "402  g_loss 0.7140353322029114\n",
            "402  d_loss 1.268786072731018\n",
            "403  g_loss 0.7153395414352417\n",
            "403  d_loss 1.3078714609146118\n",
            "404  g_loss 0.7273573875427246\n",
            "404  d_loss 1.2917757034301758\n",
            "405  g_loss 0.7170485258102417\n",
            "405  d_loss 1.3139467239379883\n",
            "406  g_loss 0.7148227691650391\n",
            "406  d_loss 1.3336381912231445\n",
            "407  g_loss 0.7167955636978149\n",
            "407  d_loss 1.3519604206085205\n",
            "408  g_loss 0.7113552689552307\n",
            "408  d_loss 1.3242595195770264\n",
            "409  g_loss 0.7599316239356995\n",
            "409  d_loss 1.233015775680542\n",
            "410  g_loss 0.7672397494316101\n",
            "410  d_loss 1.1884820461273193\n",
            "411  g_loss 0.8024869561195374\n",
            "411  d_loss 1.2706172466278076\n",
            "412  g_loss 0.8547443747520447\n",
            "412  d_loss 1.1953274011611938\n",
            "413  g_loss 0.8912354707717896\n",
            "413  d_loss 1.1801129579544067\n",
            "414  g_loss 0.9547518491744995\n",
            "414  d_loss 1.1080713272094727\n",
            "415  g_loss 0.9973344206809998\n",
            "415  d_loss 1.126231074333191\n",
            "416  g_loss 0.9873263835906982\n",
            "416  d_loss 1.0958366394042969\n",
            "417  g_loss 0.9923712015151978\n",
            "417  d_loss 1.1010698080062866\n",
            "418  g_loss 0.9296453595161438\n",
            "418  d_loss 1.1819859743118286\n",
            "419  g_loss 0.8933310508728027\n",
            "419  d_loss 1.1895402669906616\n",
            "420  g_loss 0.7550251483917236\n",
            "420  d_loss 1.4456888437271118\n",
            "421  g_loss 0.7559850811958313\n",
            "421  d_loss 1.3929119110107422\n",
            "422  g_loss 0.8202530145645142\n",
            "422  d_loss 1.3380615711212158\n",
            "423  g_loss 0.8425090312957764\n",
            "423  d_loss 1.334744930267334\n",
            "424  g_loss 0.8772401809692383\n",
            "424  d_loss 1.2104120254516602\n",
            "425  g_loss 0.9581618309020996\n",
            "425  d_loss 1.2329273223876953\n",
            "426  g_loss 0.9169057607650757\n",
            "426  d_loss 1.3579533100128174\n",
            "427  g_loss 0.9431490302085876\n",
            "427  d_loss 1.3389146327972412\n",
            "428  g_loss 0.9109572172164917\n",
            "428  d_loss 1.3258533477783203\n",
            "429  g_loss 0.9362719655036926\n",
            "429  d_loss 1.3266892433166504\n",
            "430  g_loss 0.8560121655464172\n",
            "430  d_loss 1.3981705904006958\n",
            "431  g_loss 0.8637531995773315\n",
            "431  d_loss 1.377701997756958\n",
            "432  g_loss 0.8823109269142151\n",
            "432  d_loss 1.3207945823669434\n",
            "433  g_loss 0.9126941561698914\n",
            "433  d_loss 1.3381739854812622\n",
            "434  g_loss 0.9119446277618408\n",
            "434  d_loss 1.3820984363555908\n",
            "435  g_loss 0.9278514385223389\n",
            "435  d_loss 1.3466417789459229\n",
            "436  g_loss 0.9523869156837463\n",
            "436  d_loss 1.404503583908081\n",
            "437  g_loss 0.9651215672492981\n",
            "437  d_loss 1.3675345182418823\n",
            "438  g_loss 0.9725475311279297\n",
            "438  d_loss 1.231916904449463\n",
            "439  g_loss 0.9910492897033691\n",
            "439  d_loss 1.1985993385314941\n",
            "440  g_loss 0.9697611331939697\n",
            "440  d_loss 1.1956398487091064\n",
            "441  g_loss 0.9529285430908203\n",
            "441  d_loss 1.1870765686035156\n",
            "442  g_loss 0.8875308036804199\n",
            "442  d_loss 1.2764487266540527\n",
            "443  g_loss 0.8607543706893921\n",
            "443  d_loss 1.2761602401733398\n",
            "444  g_loss 0.8892190456390381\n",
            "444  d_loss 1.2164196968078613\n",
            "445  g_loss 0.9598743915557861\n",
            "445  d_loss 1.124310851097107\n",
            "446  g_loss 1.0016013383865356\n",
            "446  d_loss 1.1009315252304077\n",
            "447  g_loss 1.0103635787963867\n",
            "447  d_loss 1.135042428970337\n",
            "448  g_loss 1.0054384469985962\n",
            "448  d_loss 1.1627718210220337\n",
            "449  g_loss 1.0005829334259033\n",
            "449  d_loss 1.175029993057251\n",
            "450  g_loss 0.9867691397666931\n",
            "450  d_loss 1.1918890476226807\n",
            "451  g_loss 0.9790931940078735\n",
            "451  d_loss 1.161367654800415\n",
            "452  g_loss 0.9577159285545349\n",
            "452  d_loss 1.2027983665466309\n",
            "453  g_loss 0.9291254878044128\n",
            "453  d_loss 1.171586036682129\n",
            "454  g_loss 0.8931611776351929\n",
            "454  d_loss 1.1385219097137451\n",
            "455  g_loss 0.8749621510505676\n",
            "455  d_loss 1.1195119619369507\n",
            "456  g_loss 0.7658801078796387\n",
            "456  d_loss 1.2359228134155273\n",
            "457  g_loss 0.7306670546531677\n",
            "457  d_loss 1.3254117965698242\n",
            "458  g_loss 0.7212004065513611\n",
            "458  d_loss 1.3121750354766846\n",
            "459  g_loss 0.7449983358383179\n",
            "459  d_loss 1.2651605606079102\n",
            "460  g_loss 0.7899135947227478\n",
            "460  d_loss 1.221713900566101\n",
            "461  g_loss 0.9131101965904236\n",
            "461  d_loss 1.0954809188842773\n",
            "462  g_loss 0.9481386542320251\n",
            "462  d_loss 1.130558967590332\n",
            "463  g_loss 0.9703371524810791\n",
            "463  d_loss 1.1310648918151855\n",
            "464  g_loss 0.9866796135902405\n",
            "464  d_loss 1.1321518421173096\n",
            "465  g_loss 0.9769334197044373\n",
            "465  d_loss 1.1343059539794922\n",
            "466  g_loss 0.9740722179412842\n",
            "466  d_loss 1.1495215892791748\n",
            "467  g_loss 0.958092212677002\n",
            "467  d_loss 1.1129649877548218\n",
            "468  g_loss 0.9562599658966064\n",
            "468  d_loss 1.052779197692871\n",
            "469  g_loss 0.8963117599487305\n",
            "469  d_loss 1.1382098197937012\n",
            "470  g_loss 0.8738561868667603\n",
            "470  d_loss 1.1082770824432373\n",
            "471  g_loss 0.8650269508361816\n",
            "471  d_loss 1.1066495180130005\n",
            "472  g_loss 0.7841668725013733\n",
            "472  d_loss 1.2160426378250122\n",
            "473  g_loss 0.7914416790008545\n",
            "473  d_loss 1.1813485622406006\n",
            "474  g_loss 0.7601639628410339\n",
            "474  d_loss 1.2102645635604858\n",
            "475  g_loss 0.753284215927124\n",
            "475  d_loss 1.2283124923706055\n",
            "476  g_loss 0.7522168755531311\n",
            "476  d_loss 1.2560131549835205\n",
            "477  g_loss 0.7670563459396362\n",
            "477  d_loss 1.2663955688476562\n",
            "478  g_loss 0.7667423486709595\n",
            "478  d_loss 1.2419278621673584\n",
            "479  g_loss 0.8219205141067505\n",
            "479  d_loss 1.245795726776123\n",
            "480  g_loss 0.8450073003768921\n",
            "480  d_loss 1.2019654512405396\n",
            "481  g_loss 0.8452335596084595\n",
            "481  d_loss 1.1859550476074219\n",
            "482  g_loss 0.8239990472793579\n",
            "482  d_loss 1.1948363780975342\n",
            "483  g_loss 0.8931918144226074\n",
            "483  d_loss 1.1118495464324951\n",
            "484  g_loss 0.8661597371101379\n",
            "484  d_loss 1.1147313117980957\n",
            "485  g_loss 0.8544484376907349\n",
            "485  d_loss 1.136411190032959\n",
            "486  g_loss 0.7983046770095825\n",
            "486  d_loss 1.231041669845581\n",
            "487  g_loss 0.840399980545044\n",
            "487  d_loss 1.1866004467010498\n",
            "488  g_loss 0.8695712089538574\n",
            "488  d_loss 1.2815409898757935\n",
            "489  g_loss 0.9561328291893005\n",
            "489  d_loss 1.1758331060409546\n",
            "490  g_loss 0.9979075193405151\n",
            "490  d_loss 1.1478606462478638\n",
            "491  g_loss 1.0724483728408813\n",
            "491  d_loss 1.1918606758117676\n",
            "492  g_loss 1.0844848155975342\n",
            "492  d_loss 1.3028862476348877\n",
            "493  g_loss 1.096105933189392\n",
            "493  d_loss 1.2888741493225098\n",
            "494  g_loss 1.0032551288604736\n",
            "494  d_loss 1.2910711765289307\n",
            "495  g_loss 0.9376875162124634\n",
            "495  d_loss 1.3483099937438965\n",
            "496  g_loss 0.8855648040771484\n",
            "496  d_loss 1.4154021739959717\n",
            "497  g_loss 0.8481088876724243\n",
            "497  d_loss 1.4315942525863647\n",
            "498  g_loss 0.7732872366905212\n",
            "498  d_loss 1.5053155422210693\n",
            "499  g_loss 0.8048800826072693\n",
            "499  d_loss 1.42542564868927\n",
            "500  g_loss 0.7960255146026611\n",
            "500  d_loss 1.431706428527832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "501  g_loss 0.8292044997215271\n",
            "501  d_loss 1.2800405025482178\n",
            "502  g_loss 0.8317092657089233\n",
            "502  d_loss 1.3144090175628662\n",
            "503  g_loss 0.8980922698974609\n",
            "503  d_loss 1.3097920417785645\n",
            "504  g_loss 0.9190289974212646\n",
            "504  d_loss 1.2810559272766113\n",
            "505  g_loss 0.9941084980964661\n",
            "505  d_loss 1.239613652229309\n",
            "506  g_loss 0.998464047908783\n",
            "506  d_loss 1.184538722038269\n",
            "507  g_loss 1.0216301679611206\n",
            "507  d_loss 1.152845025062561\n",
            "508  g_loss 1.0391157865524292\n",
            "508  d_loss 1.1396182775497437\n",
            "509  g_loss 1.0449113845825195\n",
            "509  d_loss 1.062534213066101\n",
            "510  g_loss 1.0230944156646729\n",
            "510  d_loss 1.0454440116882324\n",
            "511  g_loss 1.0194833278656006\n",
            "511  d_loss 1.0508376359939575\n",
            "512  g_loss 1.000247836112976\n",
            "512  d_loss 1.0640169382095337\n",
            "513  g_loss 1.013935923576355\n",
            "513  d_loss 1.0623767375946045\n",
            "514  g_loss 0.9549675583839417\n",
            "514  d_loss 1.074341893196106\n",
            "515  g_loss 0.9317483305931091\n",
            "515  d_loss 1.1110560894012451\n",
            "516  g_loss 0.8706883192062378\n",
            "516  d_loss 1.1529953479766846\n",
            "517  g_loss 0.841925859451294\n",
            "517  d_loss 1.216334342956543\n",
            "518  g_loss 0.8175617456436157\n",
            "518  d_loss 1.2158195972442627\n",
            "519  g_loss 0.8336056470870972\n",
            "519  d_loss 1.2328946590423584\n",
            "520  g_loss 0.9051165580749512\n",
            "520  d_loss 1.1363551616668701\n",
            "521  g_loss 0.9641695022583008\n",
            "521  d_loss 1.0871316194534302\n",
            "522  g_loss 1.0159636735916138\n",
            "522  d_loss 1.0759079456329346\n",
            "523  g_loss 1.0740516185760498\n",
            "523  d_loss 1.160480260848999\n",
            "524  g_loss 1.080892562866211\n",
            "524  d_loss 1.1860313415527344\n",
            "525  g_loss 1.0898171663284302\n",
            "525  d_loss 1.1627020835876465\n",
            "526  g_loss 1.0720505714416504\n",
            "526  d_loss 1.2035422325134277\n",
            "527  g_loss 1.0067998170852661\n",
            "527  d_loss 1.2294282913208008\n",
            "528  g_loss 0.9947717785835266\n",
            "528  d_loss 1.249950885772705\n",
            "529  g_loss 0.9145616292953491\n",
            "529  d_loss 1.233081340789795\n",
            "530  g_loss 0.762474775314331\n",
            "530  d_loss 1.375943899154663\n",
            "531  g_loss 0.6859109401702881\n",
            "531  d_loss 1.5257588624954224\n",
            "532  g_loss 0.6799432635307312\n",
            "532  d_loss 1.5574355125427246\n",
            "533  g_loss 0.7213460206985474\n",
            "533  d_loss 1.4431012868881226\n",
            "534  g_loss 0.7744198441505432\n",
            "534  d_loss 1.3769383430480957\n",
            "535  g_loss 0.9101525545120239\n",
            "535  d_loss 1.203627347946167\n",
            "536  g_loss 0.9134724140167236\n",
            "536  d_loss 1.2674834728240967\n",
            "537  g_loss 0.9395773410797119\n",
            "537  d_loss 1.2913919687271118\n",
            "538  g_loss 0.9554609656333923\n",
            "538  d_loss 1.199899673461914\n",
            "539  g_loss 0.8916919231414795\n",
            "539  d_loss 1.2840301990509033\n",
            "540  g_loss 0.9010043144226074\n",
            "540  d_loss 1.29073166847229\n",
            "541  g_loss 0.9060674905776978\n",
            "541  d_loss 1.268118143081665\n",
            "542  g_loss 0.8854100108146667\n",
            "542  d_loss 1.2238589525222778\n",
            "543  g_loss 0.8570594787597656\n",
            "543  d_loss 1.2569886445999146\n",
            "544  g_loss 0.8232820630073547\n",
            "544  d_loss 1.2684760093688965\n",
            "545  g_loss 0.8585230112075806\n",
            "545  d_loss 1.1926827430725098\n",
            "546  g_loss 0.83141028881073\n",
            "546  d_loss 1.1919381618499756\n",
            "547  g_loss 0.8240132331848145\n",
            "547  d_loss 1.1889023780822754\n",
            "548  g_loss 0.7996516227722168\n",
            "548  d_loss 1.2169511318206787\n",
            "549  g_loss 0.7807563543319702\n",
            "549  d_loss 1.2319064140319824\n",
            "550  g_loss 0.7736794352531433\n",
            "550  d_loss 1.2355146408081055\n",
            "551  g_loss 0.8000825047492981\n",
            "551  d_loss 1.1885156631469727\n",
            "552  g_loss 0.7719594240188599\n",
            "552  d_loss 1.2063989639282227\n",
            "553  g_loss 0.7881447076797485\n",
            "553  d_loss 1.1871142387390137\n",
            "554  g_loss 0.7891279458999634\n",
            "554  d_loss 1.1995524168014526\n",
            "555  g_loss 0.7870855331420898\n",
            "555  d_loss 1.217003583908081\n",
            "556  g_loss 0.8073447942733765\n",
            "556  d_loss 1.166428565979004\n",
            "557  g_loss 0.7997841835021973\n",
            "557  d_loss 1.1790469884872437\n",
            "558  g_loss 0.8097347617149353\n",
            "558  d_loss 1.155027151107788\n",
            "559  g_loss 0.8120095729827881\n",
            "559  d_loss 1.198209285736084\n",
            "560  g_loss 0.854226291179657\n",
            "560  d_loss 1.1417468786239624\n",
            "561  g_loss 0.8665798306465149\n",
            "561  d_loss 1.1599881649017334\n",
            "562  g_loss 0.8434010148048401\n",
            "562  d_loss 1.1939764022827148\n",
            "563  g_loss 0.836561918258667\n",
            "563  d_loss 1.1679041385650635\n",
            "564  g_loss 0.807485044002533\n",
            "564  d_loss 1.2010694742202759\n",
            "565  g_loss 0.8224754333496094\n",
            "565  d_loss 1.1878353357315063\n",
            "566  g_loss 0.7682451605796814\n",
            "566  d_loss 1.2734718322753906\n",
            "567  g_loss 0.7828412055969238\n",
            "567  d_loss 1.27619469165802\n",
            "568  g_loss 0.7713219523429871\n",
            "568  d_loss 1.3105283975601196\n",
            "569  g_loss 0.7959533333778381\n",
            "569  d_loss 1.2531828880310059\n",
            "570  g_loss 0.8393048048019409\n",
            "570  d_loss 1.2197368144989014\n",
            "571  g_loss 0.9374790787696838\n",
            "571  d_loss 1.1295812129974365\n",
            "572  g_loss 1.0256130695343018\n",
            "572  d_loss 1.049492597579956\n",
            "573  g_loss 1.050125002861023\n",
            "573  d_loss 1.0304031372070312\n",
            "574  g_loss 1.0987213850021362\n",
            "574  d_loss 0.9974715113639832\n",
            "575  g_loss 1.0960352420806885\n",
            "575  d_loss 0.9600518941879272\n",
            "576  g_loss 1.0315070152282715\n",
            "576  d_loss 1.0534350872039795\n",
            "577  g_loss 1.0412324666976929\n",
            "577  d_loss 0.9920632839202881\n",
            "578  g_loss 0.9603086113929749\n",
            "578  d_loss 1.0446416139602661\n",
            "579  g_loss 0.939484715461731\n",
            "579  d_loss 1.0509984493255615\n",
            "580  g_loss 0.8636472225189209\n",
            "580  d_loss 1.1572846174240112\n",
            "581  g_loss 0.8809256553649902\n",
            "581  d_loss 1.1339207887649536\n",
            "582  g_loss 0.8487143516540527\n",
            "582  d_loss 1.1550098657608032\n",
            "583  g_loss 0.8711283802986145\n",
            "583  d_loss 1.0924088954925537\n",
            "584  g_loss 0.9356904625892639\n",
            "584  d_loss 1.058375597000122\n",
            "585  g_loss 0.9494598507881165\n",
            "585  d_loss 1.0127629041671753\n",
            "586  g_loss 0.9880859851837158\n",
            "586  d_loss 1.0336487293243408\n",
            "587  g_loss 0.9915198087692261\n",
            "587  d_loss 1.075655221939087\n",
            "588  g_loss 1.0105592012405396\n",
            "588  d_loss 1.041511058807373\n",
            "589  g_loss 0.9958754777908325\n",
            "589  d_loss 1.0752514600753784\n",
            "590  g_loss 1.017862319946289\n",
            "590  d_loss 1.0263094902038574\n",
            "591  g_loss 0.8706117272377014\n",
            "591  d_loss 1.114208459854126\n",
            "592  g_loss 0.9165828227996826\n",
            "592  d_loss 1.0766994953155518\n",
            "593  g_loss 0.9144899249076843\n",
            "593  d_loss 1.1377098560333252\n",
            "594  g_loss 0.862991452217102\n",
            "594  d_loss 1.1480798721313477\n",
            "595  g_loss 0.9257177114486694\n",
            "595  d_loss 1.0559076070785522\n",
            "596  g_loss 0.8856397867202759\n",
            "596  d_loss 1.1629493236541748\n",
            "597  g_loss 0.8794152736663818\n",
            "597  d_loss 1.1898537874221802\n",
            "598  g_loss 0.9140406250953674\n",
            "598  d_loss 1.20420503616333\n",
            "599  g_loss 1.0310258865356445\n",
            "599  d_loss 1.0597221851348877\n",
            "600  g_loss 1.0056588649749756\n",
            "600  d_loss 1.0195398330688477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "601  g_loss 1.0179753303527832\n",
            "601  d_loss 1.0668354034423828\n",
            "602  g_loss 1.0554184913635254\n",
            "602  d_loss 1.0681769847869873\n",
            "603  g_loss 0.9916607737541199\n",
            "603  d_loss 1.0574918985366821\n",
            "604  g_loss 0.8759697079658508\n",
            "604  d_loss 1.1021041870117188\n",
            "605  g_loss 0.88789963722229\n",
            "605  d_loss 1.0950345993041992\n",
            "606  g_loss 0.8607437610626221\n",
            "606  d_loss 1.1507043838500977\n",
            "607  g_loss 0.9226773977279663\n",
            "607  d_loss 1.064910650253296\n",
            "608  g_loss 0.9649515748023987\n",
            "608  d_loss 1.0898559093475342\n",
            "609  g_loss 1.1167356967926025\n",
            "609  d_loss 1.0057770013809204\n",
            "610  g_loss 1.1941654682159424\n",
            "610  d_loss 0.947697639465332\n",
            "611  g_loss 1.2686820030212402\n",
            "611  d_loss 1.0725009441375732\n",
            "612  g_loss 1.2669482231140137\n",
            "612  d_loss 0.9014875888824463\n",
            "613  g_loss 1.2381768226623535\n",
            "613  d_loss 0.9164122939109802\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}